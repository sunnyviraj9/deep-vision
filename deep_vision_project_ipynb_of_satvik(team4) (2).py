# -*- coding: utf-8 -*-
"""Deep_vision_project.ipynb of Satvik(team4)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wx6BkDJ3Lgt-CXgQ7KzewRNNJjCyBGo-

# **DeepVision Crowd Monitor: AI for Density Estimation and Overcrowding Detection**
"""

!pip install torch torchvision torchaudio opencv-python-headless numpy scipy scikit-learn matplotlib pillow streamlit twilio pyngrok tqdm

"""# **Task-1**"""

import os
import cv2
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import matplotlib.pyplot as plt
import scipy.io as sio
from scipy.ndimage import gaussian_filter



class ShanghaiTechDataset(Dataset):
    def __init__(self, image_dir, gt_dir, transform=None, sigma=15):
        self.image_dir = image_dir
        self.gt_dir = gt_dir
        self.transform = transform
        self.sigma = sigma

        self.image_files = sorted([
            f for f in os.listdir(image_dir)
            if f.lower().endswith(('.jpg', '.png'))
        ])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        img_path = os.path.join(self.image_dir, img_name)


        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        gt_name = f"GT_{os.path.splitext(img_name)[0]}.mat"
        gt_path = os.path.join(self.gt_dir, gt_name)

        if not os.path.exists(gt_path):
            raise FileNotFoundError(f"Ground truth file not found: {gt_path}")

        mat = sio.loadmat(gt_path)
        points = mat["image_info"][0, 0][0, 0][0]


        density_map = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)
        for point in points:
            x, y = min(int(point[0]), img.shape[1]-1), min(int(point[1]), img.shape[0]-1)
            density_map[y, x] = 1

        density_map = gaussian_filter(density_map, sigma=self.sigma)

        if self.transform:
            img = self.transform(img)

        density_map = cv2.resize(density_map, (img.shape[2], img.shape[1]))
        density_map = torch.tensor(density_map, dtype=torch.float32).unsqueeze(0)
        return img, density_map


def visualize_sample(dataset, idx=0, save_path="visualizations/samplep.png"):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    img, gt = dataset[idx]

    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(img.permute(1, 2, 0))
    plt.title("Image")
    plt.subplot(1, 2, 2)
    plt.imshow(gt.squeeze(0), cmap="jet")
    plt.title("Density Map")
    plt.savefig(save_path)
    plt.show()


if __name__ == "__main__":
    image_dir = r"/content/drive/MyDrive/archive (1)/ShanghaiTech/part_A/train_data/images"
    gt_dir = r"/content/drive/MyDrive/archive (1)/ShanghaiTech/part_A/train_data/ground-truth"

    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Resize((512, 512))
    ])
    dataset = ShanghaiTechDataset(image_dir=image_dir, gt_dir=gt_dir, transform=transform)
    loader = DataLoader(dataset, batch_size=4, shuffle=True)
    print(f"Total samples: {len(dataset)}")

    visualize_sample(dataset, idx=0)

from google.colab import drive
drive.mount('/content/drive')

"""# **Task-2**"""

import os, glob, torch, torch.nn as nn, scipy.io as sio
import numpy as np, cv2, matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms

class CrowdDataset(Dataset):
    def __init__(self, root, train=True, size=(256,256)):
        sub = "train_data" if train else "test_data"
        imgs = sorted(glob.glob(os.path.join(root, sub, "images", ".jpg")) +
                      glob.glob(os.path.join(root, sub, "images", ".png")))
        print(f"[{sub}] Found {len(imgs)} images in {os.path.join(root,sub,'images')}")
        self.imgs = imgs
        self.gts = [p.replace("images","ground-truth").replace(".jpg",".mat").replace(".png",".mat") for p in imgs]
        self.size, self.tf = size, transforms.ToTensor()

    def __len__(self): return len(self.imgs)

    def __getitem__(self, i):
        img=cv2.imread(self.imgs[i]); img=cv2.resize(img,self.size)
        mat=sio.loadmat(self.gts[i])
        pts=mat["image_info"][0,0][0,0][0]
        den=np.zeros(self.size,np.float32)
        for x,y in pts:
            if int(y*self.size[1]/img.shape[0])<self.size[1] and int(x*self.size[0]/img.shape[1])<self.size[0]:
                den[int(y*self.size[1]/img.shape[0]), int(x*self.size[0]/img.shape[1])]=1
        den=cv2.GaussianBlur(den,(15,15),4)
        return self.tf(img), torch.tensor(den).unsqueeze(0)

class CSRNet(nn.Module):
    def __init__(self):
        super().__init__()
        vgg=list(models.vgg16(pretrained=False).features.children())
        self.front=nn.Sequential(*vgg[:23])
        self.back=nn.Sequential(
            nn.Conv2d(512,512,3,1,2,dilation=2),nn.ReLU(),
            nn.Conv2d(512,512,3,1,2,dilation=2),nn.ReLU(),
            nn.Conv2d(512,512,3,1,2,dilation=2),nn.ReLU(),
            nn.Conv2d(512,256,3,1,2,dilation=2),nn.ReLU(),
            nn.Conv2d(256,128,3,1,2,dilation=2),nn.ReLU(),
            nn.Conv2d(128,64,3,1,2,dilation=2),nn.ReLU(),
            nn.Conv2d(64,1,1))
    def forward(self,x): return self.back(self.front(x))


def train_eval(root,epochs=1):
    device="cuda" if torch.cuda.is_available() else "cpu"
    tr=DataLoader(CrowdDataset(root,True),2,shuffle=True)
    te=DataLoader(CrowdDataset(root,False),2,shuffle=False)
    model,lossf,opt=CSRNet().to(device),nn.MSELoss(),torch.optim.Adam(CSRNet().parameters(),1e-5)

    for ep in range(epochs):
        model.train()
        for x,y in tr:
            x,y=x.to(device),y.to(device)
            loss=lossf(model(x),y)
            opt.zero_grad(); loss.backward(); opt.step()
        print(f"Epoch {ep+1} Loss {loss.item():.4f}")


    model.eval()
    x,y=next(iter(te))
    with torch.no_grad(): p=model(x.to(device)).cpu()
    for i in range(min(2,len(x))):
        plt.figure(figsize=(9,3))
        plt.subplot(1,3,1); plt.imshow(x[i].permute(1,2,0)); plt.title("Image"); plt.axis("off")
        plt.subplot(1,3,2); plt.imshow(y[i][0],cmap="jet"); plt.title("GT"); plt.axis("off")
        plt.subplot(1,3,3); plt.imshow(p[i][0],cmap="jet"); plt.title("Pred"); plt.axis("off")
        plt.show()

import os
root = r"/content/drive/MyDrive/archive (1)/ShanghaiTech/part_B"
for subdir, dirs, files in os.walk(root):
    print(subdir, len(files))

"""# **Task-3**"""

import os, glob, cv2, time
import numpy as np, scipy.io as sio, matplotlib.pyplot as plt
import torch, torch.nn as nn, torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from tqdm import tqdm
from torch.cuda.amp import autocast, GradScaler

# --------------------------
# CONFIG
# --------------------------
DATA_ROOT = r"/content/drive/MyDrive/archive (1)/ShanghaiTech/part_A"
IMG_SZ = (256,256)
BATCH = 8
EPOCHS = 50
LR = 1e-5
ALERT_TH = 20.0
SIGMA = 4
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --------------------------
# Dataset
# --------------------------
class CrowdDataset(Dataset):
    def __init__(self, root="", sub="train"):
        self.tf = transforms.ToTensor()
        self.size = IMG_SZ
        img_dir = os.path.join(root, f"{'train_data' if sub=='train' else 'test_data'}","images")
        self.imgs = sorted(glob.glob(os.path.join(img_dir,"*.jpg")) +
                           glob.glob(os.path.join(img_dir,"*.png")))
        if len(self.imgs) == 0:
            raise FileNotFoundError(f"No images found in {img_dir}. Please check path.")
        self.gt_dir = os.path.join(root, f"{'train_data' if sub=='train' else 'test_data'}","ground-truth")

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self,i):
        p=self.imgs[i]
        img=cv2.cvtColor(cv2.imread(p),cv2.COLOR_BGR2RGB)
        oh,ow=img.shape[:2]
        img=cv2.resize(img,self.size)
        base=os.path.splitext(os.path.basename(p))[0]
        cand = os.path.join(self.gt_dir, f"GT_{base}.mat")
        if not os.path.exists(cand):
            cand = os.path.join(self.gt_dir, base+".mat")
        pts = np.zeros((0,2))
        if os.path.exists(cand):
            m=sio.loadmat(cand)
            try:
                pts = np.array(m["image_info"][0,0][0,0][0],dtype=np.float32)
            except Exception as e:
                print(f"[WARN] Could not parse GT file {cand}: {e}")
        if pts.size:
            pts[:,0] = pts[:,0]* (self.size[1]/ow)
            pts[:,1] = pts[:,1]* (self.size[0]/oh)
        den=np.zeros(self.size,dtype=np.float32)
        for pt in pts:
            x=int(round(pt[0])); y=int(round(pt[1]))
            if 0<=x<self.size[1] and 0<=y<self.size[0]:
                den[y,x]+=1
        den = cv2.GaussianBlur(den,(SIGMA*4+1,SIGMA*4+1),SIGMA) if den.sum()>0 else den
        return self.tf(img.astype('float32')/255.0), torch.from_numpy(den[None]).float()

# --------------------------
# Model: Tiny-MCNN
# --------------------------
class TinyMCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(3,16,3,1,1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16,32,3,1,1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32,64,3,1,1), nn.ReLU(),
            nn.Conv2d(64,1,1)
        )
    def forward(self,x):
        o=self.net(x)
        if o.shape[2:] != x.shape[2:]:
            o = F.interpolate(o, size=(x.shape[2], x.shape[3]), mode='bilinear', align_corners=False)
        return o

# --------------------------
# Training + Evaluation
# --------------------------
def train_eval(root, epochs=EPOCHS):
    torch.manual_seed(42)
    tr = DataLoader(CrowdDataset(root,'train'), batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)
    te = DataLoader(CrowdDataset(root,'test'),  batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)
    model = TinyMCNN().to(DEVICE)
    opt = torch.optim.Adam(model.parameters(), lr=LR)
    lossf = nn.MSELoss()
    scaler = GradScaler()
    train_losses=[]; val_losses=[]
    for ep in range(epochs):
        model.train(); tl=0.0
        pbar = tqdm(tr, desc=f"Epoch {ep+1}/{epochs}")
        for x,y in pbar:
            x,y=x.to(DEVICE, non_blocking=True),y.to(DEVICE, non_blocking=True)
            opt.zero_grad()
            with autocast():
                p=model(x); l=lossf(p,y)
            scaler.scale(l).backward()
            scaler.step(opt)
            scaler.update()
            tl+=l.item()
            pbar.set_postfix(loss=l.item())
        train_losses.append(tl/len(tr) if len(tr)>0 else 0)
        model.eval(); vl=0.0; preds=[]; gts=[]
        with torch.no_grad():
            for x,y in te:
                x,y=x.to(DEVICE, non_blocking=True),y.to(DEVICE, non_blocking=True)
                p=model(x); vl+=lossf(p,y).item()
                preds += p.cpu().numpy().sum(axis=(1,2,3)).tolist()
                gts += y.cpu().numpy().sum(axis=(1,2,3)).tolist()
        val_losses.append(vl/len(te) if len(te)>0 else 0)
        mae = np.mean(np.abs(np.array(preds)-np.array(gts))) if preds else 0
        rmse = (np.mean((np.array(preds)-np.array(gts))**2))**0.5 if preds else 0
        print(f"Ep{ep+1} TrLoss={train_losses[-1]:.4f} ValLoss={val_losses[-1]:.4f} MAE={mae:.2f} RMSE={rmse:.2f}")
    plt.plot(train_losses,label='train'); plt.plot(val_losses,label='val'); plt.legend(); plt.show()
    # visualize predictions
    it=iter(te); shown=0
    with torch.no_grad():
        while shown<2:
            try: x,y = next(it)
            except StopIteration: break
            p = model(x.to(DEVICE)).cpu()
            for i in range(len(x)):
                img=(x[i].permute(1,2,0).numpy()*255).astype('uint8')
                plt.figure(figsize=(9,3))
                plt.subplot(1,3,1); plt.imshow(img); plt.title('Image'); plt.axis('off')
                plt.subplot(1,3,2); plt.imshow(y[i,0],cmap='jet'); plt.title(f'GT {y[i].sum():.1f}')
                plt.subplot(1,3,3); plt.imshow(p[i,0],cmap='jet'); plt.title(f'Pred {p[i].sum():.1f}')
                plt.show(); shown+=1
                if shown>=2: break
    torch.save(model.state_dict(),"tiny_mcnn.pth")
    print("Model saved as tiny_mcnn.pth")
    return model

# --------------------------
# Realtime Inference
# --------------------------
def realtime(model, threshold=ALERT_TH, source=0):
    cap=cv2.VideoCapture(source)
    if not cap.isOpened(): print("Cannot open source"); return
    print("Press q to quit")
    prev=time.time()
    while True:
        ret,frame=cap.read()
        if not ret: break
        h,w=IMG_SZ
        frm=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB); frm=cv2.resize(frm,(w,h))
        t = transforms.ToTensor()(frm.astype('float32')/255.0).unsqueeze(0).to(DEVICE)
        with torch.no_grad(): den = model(t).cpu().squeeze().numpy()
        cnt = den.sum()
        heat = (den/den.max()*255).astype('uint8') if den.max()>0 else np.zeros_like(den,dtype='uint8')
        heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)
        overlay = cv2.addWeighted(cv2.resize(frame,(w,h)),0.6,heat,0.4,0)
        cv2.putText(overlay,f"Count:{cnt:.1f}",(10,25),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),2)
        if cnt>threshold: cv2.putText(overlay,"ALERT: OVERCROWD",(10,55),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),2)
        fps=1.0/(time.time()-prev); prev=time.time()
        cv2.putText(overlay,f"FPS:{fps:.1f}",(10,85),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,0),2)
        cv2.imshow("Crowd",overlay)
        if cv2.waitKey(1)&0xFF==ord('q'): break
    cap.release(); cv2.destroyAllWindows()

# --------------------------
# MAIN
# --------------------------
if __name__=="__main__":
    model = train_eval(DATA_ROOT, epochs=EPOCHS)
    # Uncomment to run realtime inference after training
    # model.load_state_dict(torch.load("tiny_mcnn.pth", map_location=DEVICE))
    # model.eval()
    # realtime(model, threshold=ALERT_TH, source=0)

"""# **Task-4**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_task4.py
# # ===============================
# # Milestone 4: Dashboard + Alerts
# # ===============================
# import os, smtplib, cv2, torch
# import numpy as np
# import streamlit as st
# from torchvision import transforms
# from PIL import Image
# from twilio.rest import Client
# import torch.nn as nn
# import torch.nn.functional as F
# 
# # -------------------------------
# # CONFIG
# # -------------------------------
# IMG_SZ = (256,256)
# DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ALERT_THRESHOLD = int(os.getenv("ALERT_THRESHOLD", "150"))
# 
# # -------------------------------
# # Model (Tiny-MCNN from Milestone 3)
# # -------------------------------
# class TinyMCNN(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.net = nn.Sequential(
#             nn.Conv2d(3,16,3,1,1), nn.ReLU(), nn.MaxPool2d(2),
#             nn.Conv2d(16,32,3,1,1), nn.ReLU(), nn.MaxPool2d(2),
#             nn.Conv2d(32,64,3,1,1), nn.ReLU(),
#             nn.Conv2d(64,1,1)
#         )
#     def forward(self,x):
#         o=self.net(x)
#         if o.shape[2:] != x.shape[2:]:
#             o = F.interpolate(o, size=(x.shape[2], x.shape[3]), mode='bilinear', align_corners=False)
#         return o
# 
# # -------------------------------
# # Load model
# # -------------------------------
# MODEL_PATH = "/content/tiny_mcnn.pth"
# model = TinyMCNN().to(DEVICE)
# if os.path.exists(MODEL_PATH):
#     model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
#     model.eval()
# else:
#     st.error("‚ùå Model file not found. Please place tiny_mcnn.pth in app folder.")
# 
# # -------------------------------
# # Preprocess function
# # -------------------------------
# def predict_count(img: Image.Image):
#     tf = transforms.ToTensor()
#     img_resized = img.resize(IMG_SZ)
#     t = tf(np.array(img_resized).astype('float32')/255.0).unsqueeze(0).to(DEVICE)
#     with torch.no_grad():
#         den = model(t).cpu().squeeze().numpy()
#     cnt = float(den.sum())
#     return cnt, den
# 
# # -------------------------------
# # Alert functions
# # -------------------------------
# def send_email(subject, body):
#     try:
#         EMAIL_USER = os.getenv("EMAIL_USER")
#         EMAIL_PASS = os.getenv("EMAIL_PASS")
#         ALERT_EMAIL = os.getenv("ALERT_EMAIL")
#         msg = f"Subject:{subject}\n\n{body}"
#         with smtplib.SMTP_SSL("smtp.gmail.com", 465) as smtp:
#             smtp.login(EMAIL_USER, EMAIL_PASS)
#             smtp.sendmail(EMAIL_USER, ALERT_EMAIL, msg)
#         st.success("üìß Email alert sent!")
#     except Exception as e:
#         st.error(f"Email failed: {e}")
# 
# def send_sms(body):
#     try:
#         TWILIO_SID = os.getenv("TWILIO_SID")
#         TWILIO_TOKEN = os.getenv("TWILIO_TOKEN")
#         TWILIO_FROM = os.getenv("TWILIO_FROM")
#         ALERT_PHONE = os.getenv("ALERT_PHONE")
#         client = Client(TWILIO_SID, TWILIO_TOKEN)
#         client.messages.create(body=body, from_=TWILIO_FROM, to=ALERT_PHONE)
#         st.success("üì± SMS alert sent!")
#     except Exception as e:
#         st.error(f"SMS failed: {e}")
# 
# # -------------------------------
# # Streamlit Dashboard
# # -------------------------------
# st.set_page_config(page_title="Crowd Counting Dashboard", layout="wide")
# st.title("üßë‚Äçü§ù‚Äçüßë Real-Time Crowd Counting Dashboard")
# 
# uploaded = st.file_uploader("Upload a crowd image", type=["jpg","png","jpeg"])
# if uploaded:
#     img = Image.open(uploaded).convert("RGB")
#     st.image(img, caption="Uploaded Image", use_column_width=True)
# 
#     # prediction
#     count, density = predict_count(img)
#     st.metric("Estimated Crowd Count", f"{count:.1f}")
#     status = "‚ö†Ô∏è High Crowd!" if count > ALERT_THRESHOLD else "‚úÖ Normal"
#     st.metric("Status", status)
# 
#     # show density heatmap
#     import matplotlib.pyplot as plt
#     import io
#     fig, ax = plt.subplots()
#     ax.imshow(density, cmap="jet")
#     ax.set_title("Predicted Density Map")
#     buf = io.BytesIO()
#     plt.savefig(buf, format="png")
#     st.image(buf)
# 
#     # alert button
#     if count > ALERT_THRESHOLD:
#         if st.button("üö® Send Alert"):
#             msg = f"Crowd Alert! Count reached {count:.1f}"
#             send_email("Crowd Alert", msg)
#             send_sms(msg)
#

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_task4.py
# # ===============================
# # Milestone 4: Dashboard + Alerts (Styled)
# # ===============================
# import os, smtplib, cv2, torch
# import numpy as np
# import streamlit as st
# from torchvision import transforms
# from PIL import Image
# from twilio.rest import Client
# import torch.nn as nn
# import torch.nn.functional as F
# 
# # -------------------------------
# # CONFIG
# # -------------------------------
# IMG_SZ = (256,256)
# DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ALERT_THRESHOLD = int(os.getenv("ALERT_THRESHOLD", "150"))
# 
# # -------------------------------
# # Model (Tiny-MCNN from Milestone 3)
# # -------------------------------
# class TinyMCNN(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.net = nn.Sequential(
#             nn.Conv2d(3,16,3,1,1), nn.ReLU(), nn.MaxPool2d(2),
#             nn.Conv2d(16,32,3,1,1), nn.ReLU(), nn.MaxPool2d(2),
#             nn.Conv2d(32,64,3,1,1), nn.ReLU(),
#             nn.Conv2d(64,1,1)
#         )
#     def forward(self,x):
#         o=self.net(x)
#         if o.shape[2:] != x.shape[2:]:
#             o = F.interpolate(o, size=(x.shape[2], x.shape[3]), mode='bilinear', align_corners=False)
#         return o
# 
# # -------------------------------
# # Load model
# # -------------------------------
# MODEL_PATH = "/content/tiny_mcnn (1).pth"
# model = TinyMCNN().to(DEVICE)
# if os.path.exists(MODEL_PATH):
#     model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
#     model.eval()
# else:
#     st.error("‚ùå Model file not found. Please place tiny_mcnn.pth in app folder.")
# 
# # -------------------------------
# # Preprocess function
# # -------------------------------
# def predict_count(img: Image.Image):
#     tf = transforms.ToTensor()
#     img_resized = img.resize(IMG_SZ)
#     t = tf(np.array(img_resized).astype('float32')/255.0).unsqueeze(0).to(DEVICE)
#     with torch.no_grad():
#         den = model(t).cpu().squeeze().numpy()
#     cnt = float(den.sum())
#     return cnt, den
# 
# # -------------------------------
# # Alert functions
# # -------------------------------
# def send_email(subject, body):
#     try:
#         EMAIL_USER = os.getenv("EMAIL_USER")
#         EMAIL_PASS = os.getenv("EMAIL_PASS")
#         ALERT_EMAIL = os.getenv("ALERT_EMAIL")
#         msg = f"Subject:{subject}\n\n{body}"
#         with smtplib.SMTP_SSL("smtp.gmail.com", 465) as smtp:
#             smtp.login(EMAIL_USER, EMAIL_PASS)
#             smtp.sendmail(EMAIL_USER, ALERT_EMAIL, msg)
#         st.success("üìß Email alert sent!")
#     except Exception as e:
#         st.error(f"Email failed: {e}")
# 
# def send_sms(body):
#     try:
#         TWILIO_SID = os.getenv("TWILIO_SID")
#         TWILIO_TOKEN = os.getenv("TWILIO_TOKEN")
#         TWILIO_FROM = os.getenv("TWILIO_FROM")
#         ALERT_PHONE = os.getenv("ALERT_PHONE")
#         client = Client(TWILIO_SID, TWILIO_TOKEN)
#         client.messages.create(body=body, from_=TWILIO_FROM, to=ALERT_PHONE)
#         st.success("üì± SMS alert sent!")
#     except Exception as e:
#         st.error(f"SMS failed: {e}")
# 
# # -------------------------------
# # Streamlit Styling
# # -------------------------------
# st.set_page_config(page_title="Crowd Counting Dashboard", layout="wide")
# 
# st.markdown("""
#     <style>
#     body {
#         background-color: #000000;
#         color: #FFFFFF;
#     }
#     .stApp {
#         background: linear-gradient(180deg, #111111, #000000);
#         color: white;
#     }
#     .stButton>button {
#         background-color: #FFD700 !important;
#         color: black !important;
#         font-weight: bold !important;
#         border-radius: 12px !important;
#         padding: 0.6em 1.2em !important;
#         border: none !important;
#         transition: 0.3s;
#     }
#     .stButton>button:hover {
#         background-color: #FFC300 !important;
#         transform: scale(1.05);
#     }
#     .stMetric {
#         background: #1c1c1c;
#         padding: 15px;
#         border-radius: 10px;
#         box-shadow: 0px 0px 8px rgba(255,215,0,0.6);
#     }
#     h1, h2, h3, h4 {
#         color: #FFD700 !important;
#     }
#     </style>
# """, unsafe_allow_html=True)
# 
# # -------------------------------
# # Dashboard
# # -------------------------------
# st.title("üßë‚Äçü§ù‚Äçüßë Real-Time Crowd Counting Dashboard")
# 
# uploaded = st.file_uploader("üì§ Upload a crowd image", type=["jpg","png","jpeg"])
# if uploaded:
#     img = Image.open(uploaded).convert("RGB")
#     st.image(img, caption="üì∑ Uploaded Image", use_column_width=True)
# 
#     # prediction
#     count, density = predict_count(img)
#     col1, col2 = st.columns(2)
#     with col1:
#         st.metric("Estimated Crowd Count", f"{count:.1f}")
#     with col2:
#         status = "‚ö†Ô∏è High Crowd!" if count > ALERT_THRESHOLD else "‚úÖ Normal"
#         st.metric("Status", status)
# 
#     # show density heatmap
#     import matplotlib.pyplot as plt
#     import io
#     fig, ax = plt.subplots()
#     ax.imshow(density, cmap="jet")
#     ax.set_title("Predicted Density Map", color="white")
#     ax.axis("off")
#     buf = io.BytesIO()
#     plt.savefig(buf, format="png", facecolor="black")
#     st.image(buf, caption="Density Heatmap")
# 
#     # alert button
#     if count > ALERT_THRESHOLD:
#         if st.button("üö® Send Alert"):
#             msg = f"Crowd Alert! Count reached {count:.1f}"
#             send_email("Crowd Alert", msg)
#             send_sms(msg)
#

!pip install -q streamlit pyngrok twilio opencv-python-headless matplotlib pillow scipy

import os
os.environ["TWILIO_SID"] = "ACe7c23e091e8287cbba81d1b7b9c4a0ee"
os.environ["TWILIO_TOKEN"] = "9244ccfaaffa0cf302816b44569a6c1b"
os.environ["TWILIO_FROM"] = "+12694481785"
os.environ["ALERT_PHONE"] = "+916300419322"

os.environ["EMAIL_USER"] = "sunnyviraj9@gmail.com"
os.environ["EMAIL_PASS"] = "fviomtedtgkhoija"
os.environ["ALERT_EMAIL"] = "sunnyviraj9@gmail.com"

os.environ["NGROK_AUTH_TOKEN"] = "33SlxLpVlmucL8IDXAvIMyaEXjU_7eLA5GJcoY5JJSe64Pdiv"   # optional but recommended

from pyngrok import ngrok
import time
import os

# set ngrok auth directly (paste your token here)
ngrok.set_auth_token("33SlxLpVlmucL8IDXAvIMyaEXjU_7eLA5GJcoY5JJSe64Pdiv")

# start streamlit
get_ipython().system_raw("streamlit run app_task4.py --server.port 8501 --server.address 0.0.0.0 &")
time.sleep(3)

# connect to ngrok tunnel
public_url = ngrok.connect(8501)
print("üåç Open this link:", public_url.public_url)



